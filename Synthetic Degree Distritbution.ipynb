{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b622f5c-849f-44c8-92bf-17feb76b3058",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44e745fc-0752-4450-9ae9-686a8eddd41f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_synthetic_distribution(params, plot=True):\n",
    "\n",
    "    slope = params.get('slope', -2)\n",
    "    min_degree = params.get('min_degree', 1)\n",
    "    max_degree = params.get('max_degree', 200_000)\n",
    "    max_prob = params.get('max_prob', 0.5)\n",
    "\n",
    "    # Create an array of degrees from min_degree to max_degree as floats\n",
    "    degrees = np.arange(min_degree, max_degree + 1, dtype=float)\n",
    "\n",
    "    # Calculate the scaling factor A to ensure the maximum probability at min_degree\n",
    "    A = max_prob / (min_degree ** slope)\n",
    "\n",
    "    # Compute the power-law decay values\n",
    "    y_values = A * degrees ** slope\n",
    "\n",
    "    # Convert degrees to integers for dictionary keys\n",
    "    degrees_int = degrees.astype(int)\n",
    "\n",
    "    # Create a dictionary mapping degrees to decay values\n",
    "    decay_dict = dict(zip(degrees_int, y_values))\n",
    "\n",
    "    return decay_dict\n",
    "\n",
    "params = {\n",
    "    'slope': -2,\n",
    "    'intercept': 0.8,\n",
    "    'r_squared': 0.98,\n",
    "    'max_degree': 200_000,\n",
    "    'min_degree': 1,\n",
    "    'max_prob': 0.5,\n",
    "    'degree_range': list(np.arange(1, 200_000))\n",
    "}\n",
    "\n",
    "target_distribution = create_synthetic_distribution(params, 200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5722453a-11b5-453e-aa42-9cc718b97f5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType\n",
    "import random\n",
    "\n",
    "# spark = SparkSession.builder.master(\"local[*]\").appName(\"NetworkFlowGraph\").getOrCreate()\n",
    "\n",
    "def random_node():\n",
    "    # return '.'.join(map(str, np.random.randint(0, 256, size=4).tolist()))\n",
    "    return int(np.random.randint(1_000_000, 10_000_000_000))\n",
    "\n",
    "def random_feature():\n",
    "    return int(np.random.randint(1, 70000))  # cast to native int\n",
    "\n",
    "def random_col_e():\n",
    "    return str(np.random.choice(['col_e_A', 'col_e_B']))  # cast to native str\n",
    "\n",
    "num_graphs = spark.sparkContext.defaultParallelism # number of cores available\n",
    "num_nodes_per_graph = 1_000\n",
    "seed = 42\n",
    "\n",
    "seed_bc = spark.sparkContext.broadcast(seed)\n",
    "\n",
    "def configuration_model_with_distribution(n, degree_distribution):\n",
    "    \"\"\"\n",
    "    Generate a graph with a specific degree distribution\n",
    "    \"\"\"\n",
    "\n",
    "    degrees = []\n",
    "    remaining_nodes = n\n",
    "\n",
    "    for degree, prob in sorted(degree_distribution.items()):\n",
    "        if remaining_nodes <= 0:\n",
    "            break\n",
    "        count = min(int(n * prob + 0.5), remaining_nodes)\n",
    "        if count > 0:\n",
    "            degrees.extend([int(degree)] * count)\n",
    "            remaining_nodes -= count\n",
    "\n",
    "    if remaining_nodes > 0:\n",
    "        min_degree = min(degree_distribution.keys())\n",
    "        degrees.extend([min_degree] * remaining_nodes)\n",
    "\n",
    "    if len(degrees) < 2:\n",
    "        degrees = [1, 1]\n",
    "\n",
    "    if sum(degrees) % 2 != 0:\n",
    "        degrees[0] += 1\n",
    "\n",
    "    try:\n",
    "        g = nx.configuration_model(degrees, seed=42)\n",
    "        g = nx.Graph(g)\n",
    "\n",
    "        if g.number_of_edges() == 0:\n",
    "            raise nx.NetworkXError(\"Generated graph has no edges\")\n",
    "\n",
    "        return g\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating graph: {e}\")\n",
    "        return nx.barabasi_ablert_graph(n, 2)\n",
    "    \n",
    "def generate_custom_graph(partition_id, num_nodes, degree_distribution, seed):\n",
    "    np.random.seed(seed + partition_id)\n",
    "    random.seed(seed + partition_id)\n",
    "\n",
    "    g = configuration_model_with_distribution(num_nodes, degree_distribution)\n",
    "\n",
    "    node_map = {node: random_node() for node in g.nodes()}\n",
    "    edges = [(node_map[edge[0]], node_map[edge[1]],\n",
    "              random_feature(), random_feature(), random_col_e())\n",
    "             for edge in g.edges()]\n",
    "    \n",
    "    return edges\n",
    "\n",
    "target_distribution_bc = spark.sparkContext.broadcast(target_distribution)\n",
    "\n",
    "generate_custom_graph_udf = udf(\n",
    "    lambda partition_id: generate_custom_graph(\n",
    "        partition_id, num_nodes_per_graph, target_distribution_bc.value, seed_bc.value\n",
    "    ),\n",
    "    ArrayType(StructType([\n",
    "        StructField(\"col_a\", StringType(), False),\n",
    "        StructField(\"col_b\", StringType(), False),\n",
    "        StructField(\"col_c\", IntegerType(), False),\n",
    "        StructField(\"col_d\", IntegerType(), False),\n",
    "        StructField(\"col_e\", StringType(), False),\n",
    "    ]))\n",
    ")\n",
    "\n",
    "rdd = spark.range(num_graphs).withColumn(\"edges\", generate_custom_graph_udf(\"id\"))\n",
    "\n",
    "all_edges = rdd.select(\"edges\").rdd.flatMap(lambda row: row.edges).distinct()\n",
    "edge_df = all_edges.toDF([\"col_a\", \"col_b\", \"col_c\", \"col_d\", \"col_e\"])\n",
    "\n",
    "edge_count = edge_df.count()\n",
    "\n",
    "nodes = edge_df.select(\"col_a\").union(edge_df.select(\"col_b\")).distinct()\n",
    "node_count = nodes.count()\n",
    "\n",
    "average_degree = edge_df.groupBy(\"col_a\").count().agg({\"count\": \"avg\"}).first()[0]\n",
    "\n",
    "print(f\"Total edges in graph: {edge_count}\")\n",
    "print(f\"Total nodes in graph: {node_count}\")\n",
    "print(f\"Average degree: {average_degree}\")\n",
    "\n",
    "def print_graph_stats(edge_df, display=False):\n",
    "\n",
    "    unique_nodes = edge_df.select(\"col_a\").union(edge_df.select(\"col_b\")).distinct()\n",
    "\n",
    "    total_edges = edge_df.count()\n",
    "\n",
    "    src_degrees = edge_df.groupBy(\"col_a\").agg({\"col_a\": \"count\"}) \\\n",
    "        .withColumnRenamed(\"count(col_a)\", \"in_degree\") \\\n",
    "        .withColumnRenamed(\"col_a\", \"merge_col\")\n",
    "\n",
    "    dst_degrees = edge_df.groupBy(\"col_b\").agg({\"col_b\": \"count\"}) \\\n",
    "        .withColumnRenamed(\"count(col_b)\", \"out_degree\") \\\n",
    "        .withColumnRenamed(\"col_b\", \"merge_col\")\n",
    "\n",
    "    total_degrees = src_degrees.join(dst_degrees, \"merge_col\", \"outer\") \\\n",
    "        .fillna(0) \\\n",
    "            .selectExpr(\n",
    "                \"merge_col\", \n",
    "                \"cast(out_degree as int) + cast(in_degree as int) as total_degree\"\n",
    "            )\n",
    "        \n",
    "    avg_degree = total_degrees.agg({\"total_degree\": \"avg\"}).collect()[0][0]\n",
    "    max_degree = total_degrees.agg({\"total_degree\": \"max\"}).collect()[0][0]\n",
    "\n",
    "    if display:\n",
    "        print(\"\\nGraph Statistics:\")\n",
    "        print(f\"Number of unique Nodes: {unique_nodes.count()}\")\n",
    "        print(f\"Number of edges: {total_edges}\")\n",
    "        print(f\"Average degree: {avg_degree:.2f}\")\n",
    "        print(f\"Maximum degree: {max_degree}\")\n",
    "\n",
    "    return total_degrees\n",
    "\n",
    "def check_degree_distribution(edge_df):\n",
    "\n",
    "    total_degrees = print_graph_stats(edge_df)\n",
    "\n",
    "    degree_dist = total_degrees.groupBy(\"total_degree\").count() \\\n",
    "        .withColumnRenamed(\"count\", \"num_vertices\")\n",
    "\n",
    "    total_nodes = total_degrees.count()\n",
    "\n",
    "    print(\"\\nResulting degree distribution:\")\n",
    "    for row in degree_dist.orderBy(\"total_degree\").collect():\n",
    "        degree = row['total_degree']\n",
    "        count = row['num_vertices']\n",
    "        percentage = count / total_nodes\n",
    "        target_percentage = target_distribution.get(degree, 0)\n",
    "        print(f\"Degree {degree}: {percentage:.4f} (Target: {target_percentage:.4f})\")\n",
    "\n",
    "print_graph_stats(edge_df, display=True)\n",
    "check_degree_distribution(edge_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2ebd77e-18d2-4b19-b7a3-3d1d79e200ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Synthetic Degree Distritbution",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}